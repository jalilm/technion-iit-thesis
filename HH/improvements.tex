\section{\eb\ Algorithm}
\label{sec:improvemnts}
In this section we  present a simplification of the \cs\ algorithm that have better performance when the trace is heavy tailed, meaning that most of the traffic is due to a small number of flows.

This algorithms holds a similar \sfa\ as the \cs\ algorithm, however it lacks the \cs\ itself and the \sea. Instead, it holds a constant size bank of exact counters. The main motivation is that in heavy tailed traces, most of the traffic is produced by the HH flows, thus it is possible to allocate about $\frac{1}{\phi}$ exact counters to measure these flows.

The usage of the \sfa\ assures that we are not propagating too many flows in the \eb\ and only measure ``heavy" flows. The cost of this simple setup manifests in the insertion operation that requires searching the $\frac{1}{\phi}$ entries to find the appropriate entry. Another drawback of this setup, is that increasing the amount of available memory and thus the size of the \sfa\ potentially will degrade the performance.  This is due to the fact that more flows now propagate to the \eb\ even though they are not ``heavy" enough.

% \subsection{Several \sfa s}
% In this suggestion, the allocated memory of the \sfa, $m_{SFA}$, is partitioned into several constant different arrays. An arriving packet, gets hashed using different hash function into different entries in each of the arrays. If the flow is present in any of the arrays, then it will be propagated to the \cs. The motivation behind this improvement, is to lower the risk of a HH not being propagated due to being hashed to the same entry as other active flows. This change will reduce the amount of times a flow should arrive until propagated to the \cs\ and thus the probability to miss it.
% \subsection{Storing Flows Fingerprints}
% In an effort to reduce the amount of memory needed by entries of the \cs\ and the \sfa, it is possible to store a fingerprint of the flow id instead of the full $104$. Such fingerprinting was introduced in~\cite{RanFP}, and it is a calculation of a pseudo-random bit-strings generated as hashes of the identifiers. This calculation have the property that if the stream contains $D\leq F$ distinct items, then fingerprints of size $O(log D)$ will suffice to ensure that no two items have a fingerprint collision. 