\section{The \multipleAlgo Algorithm}
The \multipleAlgo Algorithm follows that same motivation of the \simpleAlgo Algorithm while trying to relax its stability assumptions.
In order to achieve that, we facilitate the ability to refine a given flowset not into just two disjoint flowsets, but rather into several $2^l$ disjoint flowsets.

The motivation behind this larger refinement process is that it results in a smaller number of more stable rounds. The larger the round compared to the trace's size, the more we expect that its flows distribution is closer to the entire trace distribution. Furthermore, this way we have a lower probability of deviating from the real HH flows down the hierarchy, due to bursts of other non HH flows or fluctuations in the real HH flows.

This larger refinement process allows the algorithm to advance several levels down the hierarchy at once. Since the algorithm is still limited to $C$ counters, this comes at a cost that the algorithm can refine fewer flowsets than \simpleAlgo Algorithm at each round. If at a given round the algorithm advances $l$ levels, then to keep the limit of using $C$ counters, it should refine each of the top $\floor{\frac{C}{2^l}}$ flowsets into $2^l$ disjoint flowsets.
 
The initialization step is the same as in the \simpleAlgo Algorithm with the addition of calculating the levels step. In each step, the algorithm should decide at which levels of the hierarchy to monitor. It is clear that the first level should be $\floor{log_2(C)}$ level in order to cover the entire frontier of the trie. Furthermore, the last level should be the depth of the hierarchy $H$, in order to be able to calculate the set of candidate HH and HHH correctly.

We calculate the levels to be monitored as part of the algorithm initialization. This is needed in order for the algorithm to know how many rounds of monitoring are expected so as to partition the trace into an adequate number of parts. One might consider a dynamic approach of calculating the next level ``as we go", however, this approach has no clear advantage in performance and in addition, it imposes a new complication. Since in such a dynamic approach, not all rounds are equal, the algorithm must use estimation when calculating the conditional frequencies of suspect HHH flows, possibly as proposed in~\cite{Zhang2004}. Any such estimation step adds additional error to the final result with no clear advantage.

The rest of the algorithm is similar to the ~\simpleAlgo Algorithm, except the refining of the flowsets, which replaces each candidate flowsets into $2^l$ disjoint flowsets rather than simply two. In fact, if the calculating levels step returns all levels (starting from $log_2(C)$ up to $H$) then the algorithm converges to the ~\simpleAlgo Algorithm.

It is common to use the full byte levels ($8, 16, 24,32$ as the monitored levels~\cite{MST, BenBasat2017}.  For example, if we consider the IP\_SRC hierarchy $H=32$ with $2^{10}=1024$ counters. The initial step would be to assign the counters at level $10$ of the hierarchy. Then, at the end of the respective rounds, the algorithm will advance to levels 16, 24, and 32.
Previous works that reported HH and HHH in non 1-bit granularity limited their monitoring to that specific granularity. This means, they can not reconstruct from the non 1-bit data any insights on finer granularity HH and HHH. On the contrary, the \multipleAlgo Algorithm does not suffer from this limitation. Despite constructing the monitoring levels in non 1-bit granularity, the algorithm reconstructs the frequencies of all the inner nodes of the monitored trie.

\input{HHH/algorithms/multiple_split_alg.tex}
