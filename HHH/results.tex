\section{Evaluation}
We evaluated our algorithms using the following real life traces: (1) CAIDA'16: CAIDA Internet Traces from ``Equinix-Chicago'' in 2016~\cite{CAIDA2016}, (2) CAIDA'18: CAIDA Internet Traces from ``Equinix-NewYork'' in 2018~\cite{CAIDA2018}. We considered IP source hierarchies in a single bit granularities, such hierarchies were also used in~\cite{ben2017constant, SpaceSaving}, and considered the unweighted frequencies of items (i.e., the number of packets). Each data point is the average of 10 runs, where each run started from a randomly selected point in the given trace.

We use the \textit{Recall} and \textit{Precision} metrics proposed in ~\cite{ffMetrics} to evaluate the performance of the suggested algorithms. In order to compute these metrics, we calculated the true set of HH and HHH using a space intensive algorithm that allocates a counter per flow for exact measurements.
Recall is the number of true HHHs detected by the algorithm divided by the number of true HHHs. This metric is equivalent to the Detection Rate of the algorithm, i.e., what is the percentage of HHHs the algorithm detects.
Precision is the number of true HHHs detected by the algorithm divided by the number of reported suspect HHH. This metric complements the false positive rate of the algorithm and tries to grasp how many of the suspect HHHs the algorithm was mistaken.

We denote our proposed algorithms with ``SS" for \simpleAlgo, ``MS" for \multipleAlgo, ``HTF" for \ref{algo:htf} and ``SA" for \ref{algo:sa}. Furthermore, we use ``RHHH" to denote the algorithm proposed in~\cite{ben2017constant} and ``MST" to denote the algorithm proposed in~\cite{SpaceSaving}. These algorithms solve an approximate version of the problem with an accuracy parameter $\epsilon$, when comparing with them we expand the set of true HHH by a slack of $\epsilon T$.

\input{HHH/latex_figures/recall.tex}

Figure~\ref{fig:recall} shows the \textit{Recall} of the various algorithms as a function of the number of available counters. Each line describes a single algorithm and the CAIDA trace, the runs are on random parts of the trace of $2^{25}$ packets (about one minute of traffic) with threshold $\phi=0.001$. It is worthy to note that the performance on CAIDA'18 trace is usually better than those of CAIDA'16 trace, this is since in CAIDA'16 trace the heaviest flows are not as stable as in CAIDA'18. Also, note that the number of HH in these traces at a given level of the hierarchy is at most 200. This explains the overall poor performance when using fewer counters than 512.

When considering the Recall of ~\simpleAlgo and ~\multipleAlgo algorithms, one can notice an improvement as the number of counters increases up to a point where adding more counters does not help anymore. This limitation is explained by the lack of a retracting mechanism in these algorithms, thus missing a portion of the HHH that starts late in the monitoring interval and more specifically after the first round.

The ~\ref{algo:htf} Algorithm can not run properly for a very low number of counters, that is up to $1k$ counters. That is due to the fact that sometimes the attempt to retract the frontier does not free enough counters to perform full refinement of the interesting flowsets. Thus, we did not report the results for the number of counters where at least one run of the algorithm did not finish due to this reason. For a higher number of counters (starting from $2k$) the algorithm manages to breach the observed limitation at ~\simpleAlgo and ~\multipleAlgo algorithms due to its retracting mechanism.

The main advantage of ~\ref{algo:sa} algorithm compared to ~\ref{algo:htf} algorithm lies in the ability to deploy it using a smaller number of counters. The difference in the recall of the algorithms is not statistically significant, where both reach around 90\% recall on the CAIDA'18 traces.

\input{HHH/latex_figures/precision.tex}

Figure~\ref{fig:precision} depicts the \textit{Precision} of the various algorithms as a function of the number of available counters in the same settings as Figure~\ref{fig:recall}. More specifically, the figure shows how many flows reported by the algorithm as HHH were actually a true HHH, i.e., how precise was the algorithm in its reports. All of our algorithms tend to report most of their false positives, reported flows that are not HHH, in the higher levels of the hierarchy. Due to the parts of the hierarchy that are not monitored but still see some traffic, however, in lower levels the algorithms have a better estimation of the flow's frequencies and whether they are HHH or not. Furthermore, the higher in the hierarchy the calculation of HHH happens, the more it is prone to errors due to errors in the lower levels.

We note that the difference in precision between the two traces in a given algorithm is not that noticeable. This is explained by the fact that if even in CAIDA'16 the heaviest flows are not consistent compared to CAIDA'18, the algorithms manage to filter out flows that lead to splitting at higher levels but did not remain suspect HH throughout the rounds.

Furthermore, the trend of better performance with more counter we observed in Figure~\ref{fig:recall} is less clear especially in ~\simpleAlgo and ~\multipleAlgo algorithms. That is, sometimes more counters lead to a small decrease in the precision of the algorithms. This might be explained by the fact that with more counters these simple algorithms focus on more unimportant parts down the hierarchy.

The precision of ~\ref{algo:sa} Algorithm reaches more than 95\% for $1k$ counters and even around 97\% for more than that. This means, that given enough counters this algorithm detects around 90\% of the true HHH and reports no more than 3\% non-HHH flows. For the same reasons mentioned before, the results of ~\ref{algo:htf} Algorithm were not reported for counters less than $2k$.

\input{HHH/latex_figures/trace_length.tex}

Figure~\ref{fig:trace_length} depicts the recall of ~\ref{algo:sa} Algorithm (under the same settings) as a function of the trace length (number of packets processed) for a given number of counters. It easy to see that the algorithm does not require any convergence period in order to achieve high recall. Furthermore, there is no consistent trend in the recall of the algorithm as a function of the trace length, besides slight variations that can be explained as fluctuations in the different parts of the trace.

\input{HHH/latex_figures/trace_length_precision.tex}

Figure~\ref{fig:trace_length_precision} depicts the precision of the ~\ref{algo:sa} algorithm as function of the trace length (number of packets processed) compared to ``MST" and ``RHHH". As expected, ``RHHH" suffers from a convergence interval, only then it starts to keep its probabilistic guarantees of low false positive. ``MST", which requires $O(H)$ update time per-packet, achieves almost perfect precision (no false positive) as guaranteed by $\epsilon$. Our ~\ref{algo:sa} algorithm achieves a high precision rate averaged around 95\% regardless of the trace's length while holding $O(1)$ per-packet update time. The algorithms converge similarly on CAIDA`18 traces.
